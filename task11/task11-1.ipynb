{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "wine = datasets.load_wine()\n",
    "X = wine.data\n",
    "y = wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banyak data:  178\n"
     ]
    }
   ],
   "source": [
    "print(\"Banyak data: \", len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 data pertama: \n",
      "[[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      "  2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 1.120e+01 1.000e+02 2.650e+00 2.760e+00\n",
      "  2.600e-01 1.280e+00 4.380e+00 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 1.860e+01 1.010e+02 2.800e+00 3.240e+00\n",
      "  3.000e-01 2.810e+00 5.680e+00 1.030e+00 3.170e+00 1.185e+03]\n",
      " [1.437e+01 1.950e+00 2.500e+00 1.680e+01 1.130e+02 3.850e+00 3.490e+00\n",
      "  2.400e-01 2.180e+00 7.800e+00 8.600e-01 3.450e+00 1.480e+03]\n",
      " [1.324e+01 2.590e+00 2.870e+00 2.100e+01 1.180e+02 2.800e+00 2.690e+00\n",
      "  3.900e-01 1.820e+00 4.320e+00 1.040e+00 2.930e+00 7.350e+02]\n",
      " [1.420e+01 1.760e+00 2.450e+00 1.520e+01 1.120e+02 3.270e+00 3.390e+00\n",
      "  3.400e-01 1.970e+00 6.750e+00 1.050e+00 2.850e+00 1.450e+03]\n",
      " [1.439e+01 1.870e+00 2.450e+00 1.460e+01 9.600e+01 2.500e+00 2.520e+00\n",
      "  3.000e-01 1.980e+00 5.250e+00 1.020e+00 3.580e+00 1.290e+03]\n",
      " [1.406e+01 2.150e+00 2.610e+00 1.760e+01 1.210e+02 2.600e+00 2.510e+00\n",
      "  3.100e-01 1.250e+00 5.050e+00 1.060e+00 3.580e+00 1.295e+03]\n",
      " [1.483e+01 1.640e+00 2.170e+00 1.400e+01 9.700e+01 2.800e+00 2.980e+00\n",
      "  2.900e-01 1.980e+00 5.200e+00 1.080e+00 2.850e+00 1.045e+03]\n",
      " [1.386e+01 1.350e+00 2.270e+00 1.600e+01 9.800e+01 2.980e+00 3.150e+00\n",
      "  2.200e-01 1.850e+00 7.220e+00 1.010e+00 3.550e+00 1.045e+03]]\n"
     ]
    }
   ],
   "source": [
    "print(\"10 data pertama: \")\n",
    "print(X[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pembagian Data\n",
    "---------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Validation Split\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Banyak data latih setelah dilakukan Train-Validation Split:  124\n",
      "Banyak data uji setelah dilakukan Train-Validation Split:  54\n"
     ]
    }
   ],
   "source": [
    "print(\"Banyak data latih setelah dilakukan Train-Validation Split: \", len(X_train))\n",
    "print(\"Banyak data uji setelah dilakukan Train-Validation Split: \", len(X_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross Validation\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi model SVM untuk tiap fold:  [0.88888889 0.94444444 0.97222222 1.         1.        ]\n",
      "Akurasi model SVM dengan 5-Fold Cross Validation:  0.961111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel = 'linear', C = 1)\n",
    "scores = cross_val_score(model, X, y, cv = 5)\n",
    "print(\"Akurasi model SVM untuk tiap fold: \", scores)\n",
    "print(\"Akurasi model SVM dengan 5-Fold Cross Validation: \", scores.mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metode Klasifikasi\n",
    "-------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi dengan menggunakan Logistic Regression:  0.8888888888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alifi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Akurasi dengan menggunakan Logistic Regression: \", score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi dengan menggunakan Support Vector Machine:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "svm = SVC(\n",
    "  kernel = 'rbf',\n",
    "  C = 1,\n",
    "  gamma = 0.01\n",
    ")\n",
    "\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Akurasi dengan menggunakan Support Vector Machine: \", score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter SVM\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi dengan menggunakan Support Vector Machine Linear Kernel:  0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "# SVM dengan kernel Linear, nilai parameter C dapat diubah juga.\n",
    "svmLinear = SVC(\n",
    "  kernel = 'linear',\n",
    "  C = 1\n",
    ")\n",
    "\n",
    "svmLinear.fit(X_train, y_train)\n",
    "y_pred = svmLinear.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Akurasi dengan menggunakan Support Vector Machine Linear Kernel: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi dengan menggunakan Support Vector Machine Polynomial Kernel:  0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "# SVM dengan kernel polynomial, nilai parameter C, degree, dan gamma dapat diubah juga.\n",
    "svmPoly = SVC(\n",
    "  kernel = 'poly',\n",
    "  C = 1,\n",
    "  gamma = 0.01,\n",
    "  degree = 2\n",
    ")\n",
    "\n",
    "svmPoly.fit(X_train, y_train)\n",
    "y_pred = svmPoly.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Akurasi dengan menggunakan Support Vector Machine Polynomial Kernel: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi dengan menggunakan Support Vector Machine RBF Kernel:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# SVM dengan kernel RBF, nilai parameter C dan gamma dapat diubah juga.\n",
    "svmRBF = SVC(\n",
    "  kernel = 'rbf',\n",
    "  C = 1,\n",
    "  gamma = 0.01,\n",
    ")\n",
    "\n",
    "svmRBF.fit(X_train, y_train)\n",
    "y_pred = svmRBF.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Akurasi dengan menggunakan Support Vector Machine RBF Kernel: \", score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi dengan menggunakan Decision Tree:  0.9074074074074074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "dt = DecisionTreeClassifier(\n",
    "  max_depth = None,\n",
    "  min_samples_split = 2\n",
    ")\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Akurasi dengan menggunakan Decision Tree: \", score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Decision Tree\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi dengan menggunakan Decision Tree:  0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree dengan maximal kedalaman adalah 1 dan minimal jumlah sampel untuk dibentuk leaf baru adalah 2\n",
    "dt = DecisionTreeClassifier(\n",
    "  max_depth = 1,\n",
    "  min_samples_split = 2\n",
    ")\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Akurasi dengan menggunakan Decision Tree: \", score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi dengan menggunakan Naive Bayes:  0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "from sklearn import naive_bayes\n",
    "from sklearn import metrics\n",
    "\n",
    "nb = naive_bayes.BernoulliNB()\n",
    "\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred = nb.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Akurasi dengan menggunakan Naive Bayes: \", score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi dengan menggunakan Nearest Neighbor:  0.7407407407407407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alifi\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Akurasi dengan menggunakan Nearest Neighbor: \", score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
